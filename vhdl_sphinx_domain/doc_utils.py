""" Various Sphinx and docutils processing functions
"""

from sphinx.util.nodes import nested_parse_with_titles

from docutils import nodes
from docutils.statemachine import ViewList
from docutils.utils.code_analyzer import Lexer, LexerError
from docutils.utils import unescape

WAVEDROM_HTML = """
<div style="overflow-x:auto">
<script type="WaveDrom">
{content}
</script>
</div>
"""


def parse_rest(state, lines, class_dict={}):
    """ Parse a list of lines into a list of docutil nodes.

    Nodes are not part of a top object so sections found in the parsed text can be mede part of the parent hierarchy.
    User-specified classes can be applied to objects specified in `class_dict`.

    Parameters:

        state:

        lines (list of str): text to be parsed

        class_dict (dict): Dict in the format {object_type:class_name,...} or {object_type:[class_name, class_name...],...} that applies the specified ``class_name`` to the objects generated by the REST parser that have the tag ``object_type``

    Returns:
        list: docutil nodes

    """
    if not lines: return []
    container_node = nodes.paragraph('','')
    # print(f'Parsing text as restructuredText')
    nested_parse_with_titles(state, ViewList(lines, source=''), container_node)
    for n in container_node:
        if n.tagname in class_dict:
            # print '*** Updating class on object:', n.tagname
            if isinstance(class_dict[n.tagname], str):
                n['classes'].append(class_dict[n.tagname])
            else:
                n['classes'].extend(class_dict[n.tagname])
    return list(container_node)


def parse_markdown_table(pos, lines):
    """ Attempts to parse a block of text as a markdown table

    Parameters:

        pos (int): Line index from which markdown table decoding should be attempted

        lines (list): list of strings containing the text to decode.

    Returns:

        tuple or None: Returns the  ``(new_pos, docutils_table_node_list)`` tuple if a markdown table was found, otherwise returns None.
    """

    # Define some helper functions first
    def split_row(row):
        e = [s.strip() for s in row.strip().split('|')]
        if len(e) < 2:
            return []
        if not e[0]:
            del e[0]
        if not e[-1]:
            del e[-1]
        return e

    def skip_fence():
        nonlocal pos, lines
        if pos < len(lines) and lines[pos].strip().startswith('---'):  # if we have a top fence, skip it
            pos += 1


    # Parsing starts here
    # print 'parsing Markdown table'
    skip_fence()
    if pos+2 >= len(lines):  # not enough lines for header and separator lines
        return
    headers = split_row(lines[pos])  # attempt to decode the header row
    pos += 1
    separators = split_row(lines[pos])
    pos += 1
    if not headers or not separators:
        return  # bad separators = not a markdown table = give up
    row_entries = []
    while pos < len(lines):
        entries = split_row(lines[pos])
        # print 'row=', entries
        if not entries:
            break
        row_entries.append(entries)
        pos += 1
    if not row_entries:
        return # no rows? give up, not a markdon table
    skip_fence()
    return pos, headers, separators, row_entries

def create_table_nodes(state, headers, separators, rows, verbose=0):
    """ Converts a table specified as header row, separator rows and data rows into docutil nodes.


    Parameters:

        headers (list): list of string describing the header row

        separators (list): list of strings describing the separator row

    Returns:

        list: List of Docutil nodes (currently a list containing a single nodes.table node)

    """

    def build_row(entries, alignment):
        # return nodes.row('', *[nodes.entry('', nodes.inline('', e)) for e in entries])
        node_list = []
        for i, e in enumerate(entries):
            n = parse_rest(state, [e])
            # print '********** Element node = ', n
            entry = nodes.entry('', *n)
            if i < len(alignment) and alignment[i]:
                entry['classes'].append(alignment[i])
            node_list.append(entry)
        return nodes.row('', *node_list)

    def max_column_widths(*rows):
        """ Return the maximum width of each column. """
        widths = [0] * max(len(r) for r in rows)
        for row in rows:
            for i, entry in enumerate(row):
                widths[i] = max(widths[i], len(entry))
        return widths

    if verbose:
        print(f'We have {len(headers)} header columns, {len(separators)} separator columns, {len(rows[0])} data columns x {len(rows)}')
    widths = max_column_widths(headers, separators, *rows)
    cols = len(widths)

    # print '*** widths=', widths

    table = nodes.table()
    tgroup = nodes.tgroup('', cols=cols)
    table += tgroup

    align = []
    for i, sep in enumerate(separators):
        if sep.startswith(':') and sep.endswith(':'):
            align.append('align-center')
        elif sep.startswith(':'):
            align.append('align-left')
        elif sep.endswith(':'):
            align.append('align-right')
        else:
            align.append(None)
        tgroup += nodes.colspec(colwidth=widths[i])

    thead = nodes.thead()
    tgroup += thead

    tbody = nodes.tbody()
    tgroup += tbody
    # print '*********** building table header'
    assert len(headers) == cols, f'Header has invalid number of columns. We expected {cols} columns, but got {len(headers)} columns'
    thead += build_row(headers, align)
    for i,row in enumerate(rows):
        assert len(row) == cols, f'Data row {i}  has invalid number of columns. We expected {cols} columns but {len(row)} columns'
        tbody += build_row(row, align)



    # content = nodes.raw(text="allo les amis", format='html')
    return [table]

def create_wavedrom_reg_nodes(rows, verbose=0):
   # if (self.env.app.builder.name in ('html', 'dirhtml', 'singlehtml') and self.config.wavedrom_html_jsinline):
    wavedrom_code = """
{reg:
[
  {bits: 1,  name: '-', attr: ['x'], type: 1},
  {bits: 1,  name: '-', attr: ['x'], type: 1},
  {bits: 1,  name: '-', attr: ['x'], type: 1},
  {bits: 1,  name: '-', attr: ['x'], type: 1},
  {bits: 1,  name: 'GPIOl0', attr: ['x'], type: 3},
  {bits: 1,  name: '-', attr: ['x'], type: 1},
  {bits: 1,  name: 'GPIOl2', attr: ['x'], type: 3},
  {bits: 1,  name: 'GPIOl3', attr: ['x'], type: 3},
],
  config:{bits: 8}
}"""

    import re
    page = 'None'
    addr = 0
    wavedrom_code = []
    width = 1
    words = {}  # {addr:{bit:name}}
    for row in rows:
        if row[0]:
            page = row[0]
        # extract address range
        if row[1]:
            addr = row[1]
        #     addrs = re.split(r"\d+", row[1])
        #     if len(addr) > 1:
        #         a1, a2, *_ = addrs
        #     else:
        #         a1 = a2 = addrs[0]
        #     addr_low = min(a1, a2)
        #     addr_high = max(a1, a2)
        if row[2]:  # extract bit range
            bits = re.split(r"\D+", row[2])
            if len(bits) > 1:
                b1, b2, *_ = bits
            else:
                b1 = b2 = bits[0]
            if verbose:
                print(f'{page} {addr} {row[2]} {bits=} {b1=} {b2=}')
            lsb = min(int(b1), int(b2))
            msb = max(int(b1), int(b2))
        name = row[3]
        key = f'{page} {addr}'
        word = words.setdefault(key,{})
        for b in range(lsb, msb+1):
            word[b] = name
        # w = 8*(addr_high - addr_low + 1)
        # if w > width:
        #     width = w

        # wd_line = f"\{bits: {nbits}, name: '{name}'\}"
    if verbose:
        print(f'{words=}')

    word_lines = {}
    for word_name, bits in words.items():
        msb = max(bits.keys())
        last_bit_name = None
        width = 0
        lines = word_lines.setdefault(word_name, [])
        for b in range(msb+1):
            bit_name = bits.get(b, '(unused)')
            if not last_bit_name:
                last_bit_name = bit_name
                width = 1
            elif last_bit_name == bit_name:
                width += 1
            else:
                lines.append(f"{{bits: {width}, name: '{last_bit_name}'}}")
                last_bit_name = bit_name
                width = 1
        lines.append(f"{{bits: {width}, name: '{last_bit_name}'}}")
    if verbose:
        print(f'{word_lines=}')
    wavedrom_nodes = []
    for word_name, lines in word_lines.items():
        bit_strings = ',\n'.join(lines)
        wavedrom_code = f'{{reg: [\n{bit_strings}\n], config: {{fontsize: 8}} }}'
        if verbose:
            print(f'{word_name} = {wavedrom_code}')
        text = WAVEDROM_HTML.format(content=wavedrom_code)
        wavedrom_nodes += nodes.inline(word_name, word_name)
        wavedrom_nodes.append(nodes.raw(text=text, format='html'))
    return wavedrom_nodes


def parse_comment_block(state, lines, class_dict={}, verbose=0):
    """ Parse a block of ReStructuredText text into a node list, while also detecting and processing Markdown tables.

    Parameters:

        state: parser state to be passed to the REST parser

        lines (list of str): text to be parsed as a list of str

        class_dict (dict): classes to be applied to the REST blocks

    Returns:

        list: list of ``docutils`` nodes represting the parsed text
    """
    pos = 0
    rest_lines = []
    node_list =[]
    NL = '\n'
    while pos < len(lines):
        # Attenpts to decode text as a markdown table
        markdown_table =  parse_markdown_table(pos, lines)
        # print '*** Markdown table=', markdown_table
        if markdown_table:
            # parse lines preceding the table as normal RestructuredText
            node_list += parse_rest(state, rest_lines, class_dict)
            rest_lines.clear()
            (next_pos, headers, separators, rows) = markdown_table
            if verbose:
                print(f'VHDL Domain: A Markdown table was detected, parsed and added\n{headers=}\n{separators=}\n{NL.join(str(r) for r in rows)}')
            table_nodes = create_table_nodes(state, headers, separators, rows)
            # wavedrom_nodes = create_wavedrom_reg_nodes(rows)

            # print 'Markdown table nodes = ', table_node
            node_list.extend(table_nodes)
            # node_list.extend(wavedrom_nodes)
            node_list.append(nodes.paragraph('',''))  # make sure we don't interfere with following element
            pos = next_pos
        else:
            rest_lines.append(lines[pos])
            pos += 1

    node_list += parse_rest(state, rest_lines, class_dict)
    node_list.append(nodes.paragraph('',''))  # make sure we don't interfere with following element
    return node_list


def make_vhdl_entity_table(generics, ports):
        """ Create a table that describes the ports and generics of a VHDL entity.


        Parameters:
            generics (list): List of Namespace objects describing the generics interface. Each dict
                shall contain the ``.names``, ``.definition`` and ``.comments`` attributes.

            ports (list): Same as above, but for port interfaces.

        Returns:
            docutils.nodes.table: A Docutils table containing the specified generics and ports.

        Notes:

            The table is structured as follows::

                table
                    -tgroup
                        -colspec
                        (-thead)
                        (   -row)
                        (       -entry)
                        -tbody
                            -row
                                -entry
                                -entry
                                -...
                            -row
                            -...
        """
        COLS = 2
        table = nodes.table(classes=['vhdl_entity'])
        colspec_nodes = [nodes.colspec(colwidth=0)]*(COLS-1) + [nodes.colspec(colwidth=1)]
        tgroup = nodes.tgroup('', *colspec_nodes, cols=len(colspec_nodes))
        table += tgroup
        tbody = nodes.tbody()
        tgroup += tbody

        def add_header(name, tbody=tbody):
            tbody += nodes.row('', nodes.entry('', nodes.paragraph('','', nodes.Text(name)), morecols=COLS-1), classes=['vhdl_entity_header'])

        def add_rows(interface_elements, tbody=tbody):
            """ Add a port/generic entries to `tbody` """
            for i, interface in enumerate(interface_elements):
                identifier = ','.join(interface.names)
                definition = interface.definition
                comments = interface.comments
                def_row_class = ('vhdl_entity_def_even', 'vhdl_entity_def_odd')[i & 1]
                comments_node = nodes.inline('',comments)
                # print repr(identifier), bool(identifier)
                if not identifier:  # if just a section separating comment
                    tbody += nodes.row('',
                        nodes.entry('', comments_node, morecols=1, classes=['vhdl_entity_sep']),
                        # nodes.entry(''), #
                        classes=[def_row_class])
                else: # if an actual port definition
                    identifier_node = make_lexed_vhdl_node(identifier + ':')
                    definition_node = make_lexed_vhdl_node(definition)
                    tbody += nodes.row('',
                        nodes.entry('', identifier_node, classes=['vhdl_entity_id']), #
                        nodes.entry('', definition_node, comments_node, classes=['vhdl_entity_def']), classes=[def_row_class])

        # print generics
        if generics:
            add_header('GENERICS')
            add_rows(generics)
            # print(f'Adding generics {generics}')
        if ports:
            add_header('PORTS')
            add_rows(ports)
        return table

def make_lexed_vhdl_node(text, classes = ['highlight', 'highlight-vhdl'], options={}):
    """ Create a  node that includes the specified literal text that is colorized/highlighted by Pygments for the VHDL syntax.

    Parameters:

        text (str): literal text to insert
        classes (list): list of classes to apply to the root node
        options (dict): *unused*

    Returns:
        docutils.nodes.literal: The top node containing the highlighted text nodes, such as

    """
    tokens = Lexer(unescape(text, 1), language='vhdl', tokennames='short')  # use 'short' object names so the Sphinx highlighting CSS rules will be found
    node = nodes.literal('', '', classes=classes)  # <code> element

    # analyze content and add nodes for every token
    for pygment_classes, value in tokens:
        node += nodes.inline(value, value, classes=pygment_classes)  # <span> element
    return node
